{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d9c6b3",
   "metadata": {},
   "source": [
    "## Reading the raw HTMLs and using unstructured to chunk those HTMLs into texts and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898b8b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.html import partition_html\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import asyncio\n",
    "import time\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "from openai import AsyncOpenAI, RateLimitError, APIError, APITimeoutError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87525261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_saved_html_with_strategy(html_file_path):\n",
    "\n",
    "    try:\n",
    "        # Check if file exists\n",
    "        if not os.path.exists(html_file_path):\n",
    "            print(f\"Error: File {html_file_path} does not exist\")\n",
    "            return None\n",
    "        \n",
    "        # Partition the HTML file with section-based chunking\n",
    "        elements = partition_html(\n",
    "            filename=html_file_path,\n",
    "            infer_table_structure=True,\n",
    "            strategy=\"hi_res\",\n",
    "            chunking_strategy=\"by_title\",\n",
    "            include_page_breaks=True,\n",
    "            # Section-based chunking parameters\n",
    "            max_characters=10000,  \n",
    "            combine_text_under_n_chars= 100,  # Combine small text fragments\n",
    "            )\n",
    "        \n",
    "        return elements\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error partitioning HTML file: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88211aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCLUDED_SECTIONS = [\n",
    "    \"references\", \"reference\", \"navigation\", \"navigation menu\", \"history\",\n",
    "    \"see also\", \"notes\", \"external links\", \"trivia\", \"gallery\",\n",
    "    \"quotes\", \"bugs\", \"changelog\", \"patch history\", \"credits\",\n",
    "    \"footnotes\", \"footer\", \"acknowledgements\", \"disclaimer\"\n",
    "]\n",
    "\n",
    "def should_exclude_section(section_title: str) -> bool:\n",
    "    if not section_title:\n",
    "        return False\n",
    "    normalized = section_title.strip().lower()\n",
    "    return any(excluded in normalized for excluded in EXCLUDED_SECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7274988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_files(files):\n",
    "    texts = []\n",
    "    tables = []\n",
    "\n",
    "    for file in tqdm(files):\n",
    "        elements = partition_saved_html_with_strategy(\"raw_html/\" + file)\n",
    "\n",
    "        if not elements:\n",
    "            continue\n",
    "\n",
    "        for i in elements:\n",
    "            page_title = file.split(\".\")[0]\n",
    "            section_title = page_title\n",
    "\n",
    "            if \"CompositeElement\" in str(type(i)):\n",
    "                for j in i.metadata.orig_elements:\n",
    "                    if \"Title\" in str(type(j)):\n",
    "                        section_title = j.text.strip()\n",
    "                    elif \"Table\" in str(type(j)):\n",
    "                        if not should_exclude_section(section_title):\n",
    "                            tables.append({\n",
    "                                \"page_title\": page_title,\n",
    "                                \"section_title\": section_title,\n",
    "                                \"table\": j,\n",
    "                            })\n",
    "                    else:\n",
    "                        if not should_exclude_section(section_title):\n",
    "                            text_content = j.text.strip() if hasattr(j, \"text\") else str(j).strip()\n",
    "                            if len(text_content) >= 100:\n",
    "                                texts.append({\n",
    "                                    \"page_title\": page_title,\n",
    "                                    \"section_title\": section_title,\n",
    "                                    \"text\": text_content,\n",
    "                                })\n",
    "\n",
    "            elif \"Table\" in str(type(i)):\n",
    "                if not should_exclude_section(section_title):\n",
    "                    tables.append({\n",
    "                        \"page_title\": page_title,\n",
    "                        \"section_title\": section_title,\n",
    "                        \"table\": i,\n",
    "                    })\n",
    "            else:\n",
    "                if not should_exclude_section(section_title):\n",
    "                    text_content = i.text.strip() if hasattr(i, \"text\") else str(i).strip()\n",
    "                    if len(text_content) >= 100:\n",
    "                        texts.append({\n",
    "                            \"page_title\": page_title,\n",
    "                            \"section_title\": section_title,\n",
    "                            \"text\": text_content,\n",
    "                        })\n",
    "\n",
    "    return texts, tables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7211457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "raw_html_path = Path('raw_html')\n",
    "file_names = [f.name for f in raw_html_path.iterdir() if f.is_file()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1db5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, tables = partition_files(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ebbb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts), len(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e88921",
   "metadata": {},
   "source": [
    "## Generating a summary for each table to help us in the retrieval process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65395b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_prompt = \"\"\"\n",
    "You are an assistant tasked with summarizing the tables. \n",
    "Give a concise and short summary of the table.\n",
    "\n",
    "Respond only with the summary, no additionnal comment.\n",
    "Do not start your message by saying \"Here is a summary\" or anything like that.\n",
    "Just give the summary as it is.\n",
    "\n",
    "Table chunk: {element}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8900653",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CONCURRENT = 15          \n",
    "RETRY_LIMIT = 3\n",
    "BACKOFF_BASE = 2            # seconds to wait * attempt number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e307930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI()\n",
    "\n",
    "async def summarize_one_table(table_info, sem):\n",
    "    \"\"\"Summarize a single table with retry + backoff.\"\"\"\n",
    "    async with sem:\n",
    "        html_content = getattr(table_info[\"table\"].metadata, \"text_as_html\", \"\")\n",
    "        if not html_content:\n",
    "            table_info[\"summary\"] = \"[No table HTML]\"\n",
    "            return table_info\n",
    "\n",
    "        # truncate long tables to avoid token overflow\n",
    "        html_content = html_content[:8000]\n",
    "        prompt = summarize_prompt.format(element=html_content)\n",
    "\n",
    "        for attempt in range(RETRY_LIMIT):\n",
    "            try:\n",
    "                response = await client.chat.completions.create(\n",
    "                    model=\"gpt-5-nano\",\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    timeout=60,\n",
    "                )\n",
    "                summary = response.choices[0].message.content\n",
    "                summary = re.sub(r\"<think>.*?</think>\", \"\", summary, flags=re.DOTALL).strip()\n",
    "                table_info[\"summary\"] = summary\n",
    "                return table_info\n",
    "\n",
    "            except (RateLimitError, APIError, APITimeoutError) as e:\n",
    "                wait_time = BACKOFF_BASE * (attempt + 1)\n",
    "                print(f\"Rate/API error ({attempt+1}/{RETRY_LIMIT}) for {table_info['page_title']}: waiting {wait_time}s -> {type(e).__name__}\")\n",
    "                await asyncio.sleep(wait_time)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error ({attempt+1}/{RETRY_LIMIT}) for {table_info['page_title']}: {e}\")\n",
    "                await asyncio.sleep(2 * (attempt + 1))\n",
    "\n",
    "        table_info[\"summary\"] = \"[FAILED TO SUMMARIZE]\"\n",
    "        return table_info\n",
    "\n",
    "\n",
    "async def summarize_tables_async(tables):\n",
    "    \"\"\"Main async driver\"\"\"\n",
    "    sem = asyncio.Semaphore(MAX_CONCURRENT)\n",
    "    tasks = [summarize_one_table(t, sem) for t in tables]\n",
    "    results = await tqdm_asyncio.gather(*tasks, desc=\"Summarizing tables\", total=len(tasks))\n",
    "    return results\n",
    "\n",
    "\n",
    "def summarize_tables(tables):\n",
    "    \"\"\"Sync wrapper for normal scripts\"\"\"\n",
    "    import nest_asyncio, asyncio\n",
    "    nest_asyncio.apply()\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        if loop.is_running():\n",
    "            return asyncio.ensure_future(summarize_tables_async(tables))\n",
    "        else:\n",
    "            return loop.run_until_complete(summarize_tables_async(tables))\n",
    "    except RuntimeError:\n",
    "        return asyncio.run(summarize_tables_async(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d31182",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_tables = summarize_tables(tables)\n",
    "tables2= tables.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70380aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_tables(tables):\n",
    "    serialized = []\n",
    "    for t in tables:\n",
    "        try:\n",
    "            html = getattr(t[\"table\"].metadata, \"text_as_html\", None)\n",
    "            if not html and hasattr(t[\"table\"], \"text\"):\n",
    "                html = t[\"table\"].text\n",
    "            serialized.append({\n",
    "                \"page_title\": t[\"page_title\"],\n",
    "                \"section_title\": t[\"section_title\"],\n",
    "                \"table_html\": html or \"[No HTML available]\",\n",
    "                \"summary\": t.get(\"summary\", \"\")\n",
    "            })\n",
    "        except Exception as e:\n",
    "            serialized.append({\n",
    "                \"page_title\": t[\"page_title\"],\n",
    "                \"section_title\": t[\"section_title\"],\n",
    "                \"table_html\": \"[Serialization error]\",\n",
    "                \"summary\": t.get(\"summary\", \"\"),\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "    return serialized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4870ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_tables = serialize_tables(tables2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80ec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/summarized_tables.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(serialized_tables, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b741d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/summarized_texts.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(texts, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c538cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
